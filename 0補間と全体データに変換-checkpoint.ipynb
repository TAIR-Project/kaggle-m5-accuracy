{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "L7tBaWc-2AH1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Duplicate key in file 'C:\\\\Users\\\\User\\\\.matplotlib\\\\matplotlibrc' line #250.\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gc\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8vsxECE2AH6"
   },
   "outputs": [],
   "source": [
    "def encode_categorical(df, cols):\n",
    "    \n",
    "    for col in cols:\n",
    "        # Leave NaN as it is.\n",
    "        le = LabelEncoder()\n",
    "        #not_null = df[col][df[col].notnull()]\n",
    "        df[col] = df[col].fillna('nan')\n",
    "        df[col] = pd.Series(le.fit_transform(df[col]), index=df.index)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCErZxd82AIA"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns: #columns毎に処理\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGkCTFB_2AIH"
   },
   "outputs": [],
   "source": [
    "store_list = [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\", \"TX_1\", \"TX_2\", \"TX_3\", \"WI_1\", \"WI_2\", \"WI_3\"]\n",
    "datas = pd.DataFrame()\n",
    "for i, store in enumerate(store_list):\n",
    "    buff = pd.read_pickle(f\"{store}_interpolate.pickle\")\n",
    "    \n",
    "    #並び順を戻す\n",
    "    store = pd.read_csv(f\"add_Clean_Analysis_{store}.csv\").pipe(reduce_mem_usage)\n",
    "    store = encode_categorical(\n",
    "       store, [\"item_id\"]\n",
    "    ).pipe(reduce_mem_usage)\n",
    "    gc.collect()\n",
    "    \n",
    "    store = store[[\"item_id\", \"week\", \"wday\", \"variable\"]]\n",
    "    store[\"variable\"] = store[\"variable\"].apply(lambda x: x[-2:])\n",
    "    store[\"variable\"] = store[\"variable\"].astype(np.int8)\n",
    "    store = store.loc[store[\"variable\"] >= 13]\n",
    "    \n",
    "    # item_idの順番を整える\n",
    "    buff = pd.merge(store, buff)\n",
    "    \n",
    "    buff[\"store_id\"] = i\n",
    "    \n",
    "    # 線形補間でNaNデータを埋める\n",
    "    buff[\"sell_num\"] = buff.groupby('item_id')[\"value\"].apply(lambda group: group.interpolate())\n",
    "    \n",
    "    # 全体の固有ID値を振る\n",
    "    ids = buff[[\"item_id\"]]\n",
    "    ids = ids[~ids.duplicated()]\n",
    "    values = (3049*i) + np.arange(3049)\n",
    "    dictionary = {k: v for k, v in zip(np.array(ids[\"item_id\"]), values)}\n",
    "    buff[\"id\"] = buff[\"item_id\"].map(dictionary)\n",
    "    \n",
    "    datas = pd.concat([datas, buff])\n",
    "    #datas[datas[\"store_id\"] == i].sort_values([\"item_id\",\"date\"]).to_pickle(f\"{store}.pickle\")\n",
    "    #product[product[\"store_id\"] == i].to_pickle(f\"product_{store}.pickle\")\n",
    "    print(f\"{str(i+1)}/9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSnBhFhd2AIL"
   },
   "outputs": [],
   "source": [
    "del buff, store\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U5UYOF8f2AIP"
   },
   "outputs": [],
   "source": [
    "datas = datas[datas[\"variable\"] >= 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DLAl8jN72AIV"
   },
   "outputs": [],
   "source": [
    "datas[\"store_id\"] = datas[\"store_id\"].astype('int8')\n",
    "datas[\"id\"] = datas[\"id\"].astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1WaL4qP2AIa"
   },
   "outputs": [],
   "source": [
    "calender = pd.read_csv(\"input/calendar.csv\")\n",
    "calender = calender[calender[\"year\"] >= 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLG2zwoP2AIg"
   },
   "outputs": [],
   "source": [
    "calender.drop([\"weekday\", \"year\", \"wday\", \"month\", \"d\", \"event_type_1\", \"event_type_2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zrCstSUs2AIj"
   },
   "outputs": [],
   "source": [
    "calender = encode_categorical(\n",
    "    calender,[\"event_name_1\", \"event_name_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n",
    ").pipe(reduce_mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbxhmNv92AIo"
   },
   "outputs": [],
   "source": [
    "datas = pd.merge(datas, calender, how='left',on=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KR_icajB2AIu"
   },
   "outputs": [],
   "source": [
    "datas.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfAd9irh2AI0"
   },
   "outputs": [],
   "source": [
    "#priceも扱う\n",
    "price = pd.read_csv(\"input/sell_prices.csv\").pipe(reduce_mem_usage)\n",
    "price = encode_categorical(\n",
    "   price, [\"store_id\", \"item_id\"],\n",
    ").pipe(reduce_mem_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJa5jQKO2AI5"
   },
   "outputs": [],
   "source": [
    "calender.drop([\"event_name_1\", \"event_name_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aigQgHUN2AI-"
   },
   "outputs": [],
   "source": [
    "calender = pd.merge(calender,price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ve-PIgo32AJC"
   },
   "outputs": [],
   "source": [
    "calender.drop(\"wm_yr_wk\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OKEJZJ4h2AJF"
   },
   "outputs": [],
   "source": [
    "calender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WDRjxXus2AJJ"
   },
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFzr-_j92AJN"
   },
   "outputs": [],
   "source": [
    "datas['date'] = pd.to_datetime(datas['date'])\n",
    "calender['date'] = pd.to_datetime(calender['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hYJfGss32AJQ"
   },
   "outputs": [],
   "source": [
    "del price\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VHl_Q1Zc2AJT"
   },
   "outputs": [],
   "source": [
    "datas = pd.merge(datas, calender, on=['store_id', 'item_id', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMHlVVqb2AJX"
   },
   "outputs": [],
   "source": [
    "del calender\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opLDoaZf2AJc"
   },
   "outputs": [],
   "source": [
    "#1日前の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_1\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(1))\n",
    "\n",
    "#2日前の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_2\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(2))\n",
    "\n",
    "#7日前の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_7\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(7))\n",
    "\n",
    "#8日前\n",
    "#datas[\"prev_8\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(8))\n",
    "\n",
    "#9日前\n",
    "#datas[\"prev_9\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(9))\n",
    "\n",
    "#14日前の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_14\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(14))\n",
    "\n",
    "#############\n",
    "\n",
    "#28日前の売り上げ個数を特徴に追加\n",
    "datas[\"prev_28\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(28))\n",
    "\n",
    "#29日前の売り上げ個数を特徴に追加\n",
    "datas[\"prev_29\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(29))\n",
    "\n",
    "#30日前の売り上げ個数を特徴に追加\n",
    "datas[\"prev_30\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(30))\n",
    "\n",
    "#35日前の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_35\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(35))\n",
    "\n",
    "#半年前(182日前)の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_182\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(182))\n",
    "\n",
    "#1年前(365日前)の売り上げ個数を特徴に追加\n",
    "#datas[\"prev_365\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBSq5BBk2AJf"
   },
   "outputs": [],
   "source": [
    "#1日前の価格を特徴に追加\n",
    "datas[\"p_prev_1\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(1))\n",
    "\n",
    "#2日前の価格を特徴に追加\n",
    "#datas[\"p_prev_2\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(2))\n",
    "\n",
    "#3日前の価格を特徴に追加\n",
    "#datas[\"p_prev_3\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(3))\n",
    "\n",
    "#7日前の価格を特徴に追加\n",
    "#datas[\"p_prev_7\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(7))\n",
    "\n",
    "#14日前の価格を特徴に追加\n",
    "#datas[\"p_prev_14\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(14))\n",
    "\n",
    "#28日前の価格を特徴に追加\n",
    "#datas[\"p_prev_28\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(28))\n",
    "#あまりラグを大きくしすぎるとアイテムによってはデータが全然ない状況に..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CLqfrrox2AJj"
   },
   "outputs": [],
   "source": [
    "#for size in [7, 30]:\n",
    "#        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n",
    "#            lambda x: x.shift(7).rolling(size).mean()\n",
    "#        )\n",
    "for size in [7, 14, 28]:\n",
    "        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n",
    "            lambda x: x.shift(28).rolling(size).mean()\n",
    "        )\n",
    "#for size in [7, 30, 60, 90, 180]:\n",
    "#        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n",
    "#            lambda x: x.shift(28).rolling(size).mean()\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3jtRjhWa2AJm"
   },
   "outputs": [],
   "source": [
    "#for size in [7, 30]:\n",
    "#        datas[f\"rolling_std_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n",
    "#            lambda x: x.shift(7).rolling(size).std()\n",
    "#        )\n",
    "for size in [7, 14, 28]:\n",
    "        datas[f\"rolling_std_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n",
    "            lambda x: x.shift(28).rolling(size).std()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9ZsCOiP2AJr"
   },
   "outputs": [],
   "source": [
    "datas[\"price_change_t1\"] = (datas[\"p_prev_1\"] - datas[\"sell_price\"]) / (\n",
    "        datas[\"p_prev_1\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZnR2NJ0o2AJw"
   },
   "outputs": [],
   "source": [
    "datas[\"rolling_price_std_t7\"] = datas.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(7).std()\n",
    "    )\n",
    "datas[\"rolling_price_std_t28\"] = datas.groupby([\"id\"])[\"sell_price\"].transform(\n",
    "        lambda x: x.rolling(28).std()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pnp6k9v2AJ0"
   },
   "outputs": [],
   "source": [
    " attrs = [\n",
    "        \"year\",\n",
    "        \"quarter\",\n",
    "        \"month\",\n",
    "        \"week\",\n",
    "        \"day\",\n",
    "        \"dayofweek\",\n",
    "        #\"is_year_end\",\n",
    "        #\"is_year_start\",\n",
    "        #\"is_quarter_end\",\n",
    "        #\"is_quarter_start\",\n",
    "        #\"is_month_end\",\n",
    "        #\"is_month_start\",\n",
    "    ]\n",
    "\n",
    "for attr in attrs:\n",
    "    dtype = np.int16 if attr == \"year\" else np.int8\n",
    "    datas[attr] = getattr(datas[\"date\"].dt, attr).astype(dtype)\n",
    "\n",
    "datas[\"is_weekend\"] = datas[\"dayofweek\"].isin([5, 6]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YyqvYSzn2AJ3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kwv_iMTr2AJ8"
   },
   "outputs": [],
   "source": [
    "datas.to_pickle(\"merge_data2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pushbullet.py\n",
    "from pushbullet import Pushbullet\n",
    "pb = Pushbullet('o.JGDSmoJrTpAmJqn7rZ16geamzJK9louG')\n",
    "push = pb.push_note(\"完了\", \"★\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "0補間と全体データに変換.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
