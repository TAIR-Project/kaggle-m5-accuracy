{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport gc\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_categorical(df, cols):\n    \n    for col in cols:\n        # Leave NaN as it is.\n        le = LabelEncoder()\n        #not_null = df[col][df[col].notnull()]\n        df[col] = df[col].fillna('nan')\n        df[col] = pd.Series(le.fit_transform(df[col]), index=df.index)\n\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2    \n    for col in df.columns: #columns毎に処理\n        col_type = df[col].dtypes\n        if col_type in numerics: #numericsのデータ型の範囲内のときに処理を実行. データの最大最小値を元にデータ型を効率的なものに変更\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() / 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_list = [\"CA_1\", \"CA_2\", \"CA_3\", \"CA_4\", \"TX_1\", \"TX_2\", \"TX_3\", \"WI_1\", \"WI_2\", \"WI_3\"]\ndatas = pd.DataFrame()\nfor i, store in enumerate(store_list):\n    buff = pd.read_pickle(f\"/kaggle/input/m5mylib/{store}_interpolate.pickle\")\n    \n    #並び順を戻す\n    store = pd.read_csv(f\"/kaggle/input/m5mylib/add_Clean_Analysis_{store}.csv\").pipe(reduce_mem_usage)\n    store = encode_categorical(\n       store, [\"item_id\"]\n    ).pipe(reduce_mem_usage)\n    gc.collect()\n    \n    store = store[[\"item_id\", \"week\", \"wday\", \"variable\"]]\n    store[\"variable\"] = store[\"variable\"].apply(lambda x: x[-2:])\n    store[\"variable\"] = store[\"variable\"].astype(np.int8)\n    store = store.loc[store[\"variable\"] >= 13]\n    \n    # item_idの順番を整える\n    buff = pd.merge(store, buff)\n    \n    buff[\"store_id\"] = i\n    \n    # 線形補間でNaNデータを埋める\n    buff[\"sell_num\"] = buff.groupby('item_id')[\"value\"].apply(lambda group: group.interpolate())\n    \n    # 全体の固有ID値を振る\n    ids = buff[[\"item_id\"]]\n    ids = ids[~ids.duplicated()]\n    values = (3049*i) + np.arange(3049)\n    dictionary = {k: v for k, v in zip(np.array(ids[\"item_id\"]), values)}\n    buff[\"id\"] = buff[\"item_id\"].map(dictionary)\n    \n    datas = pd.concat([datas, buff])\n    #datas[datas[\"store_id\"] == i].sort_values([\"item_id\",\"date\"]).to_pickle(f\"{store}.pickle\")\n    #product[product[\"store_id\"] == i].to_pickle(f\"product_{store}.pickle\")\n    print(f\"{str(i+1)}/9\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del buff, store\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas = datas[datas[\"variable\"] >= 13]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas[\"store_id\"] = datas[\"store_id\"].astype('int8')\ndatas[\"id\"] = datas[\"id\"].astype(\"int16\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/calendar.csv\")\ncalender = calender[calender[\"year\"] >= 2013]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender.drop([\"weekday\", \"year\", \"wday\", \"month\", \"d\", \"event_type_1\", \"event_type_2\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender = encode_categorical(\n    calender,[\"event_name_1\", \"event_name_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"]\n).pipe(reduce_mem_usage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas = pd.merge(datas, calender, how='left',on=[\"date\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#priceも扱う\nprice = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\").pipe(reduce_mem_usage)\nprice = encode_categorical(\n   price, [\"store_id\", \"item_id\"],\n).pipe(reduce_mem_usage)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender.drop([\"event_name_1\", \"event_name_2\", \"snap_CA\", \"snap_TX\", \"snap_WI\"], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender = pd.merge(calender,price)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender.drop(\"wm_yr_wk\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calender","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas['date'] = pd.to_datetime(datas['date'])\ncalender['date'] = pd.to_datetime(calender['date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del price\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas = pd.merge(datas, calender, on=['store_id', 'item_id', 'date'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del calender\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1日前の売り上げ個数を特徴に追加\n#datas[\"prev_1\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(1))\n\n#2日前の売り上げ個数を特徴に追加\n#datas[\"prev_2\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(2))\n\n#7日前の売り上げ個数を特徴に追加\n#datas[\"prev_7\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(7))\n\n#8日前\n#datas[\"prev_8\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(8))\n\n#9日前\n#datas[\"prev_9\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(9))\n\n#14日前の売り上げ個数を特徴に追加\n#datas[\"prev_14\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(14))\n\n#############\n\n#28日前の売り上げ個数を特徴に追加\ndatas[\"prev_28\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(28))\n\n#29日前の売り上げ個数を特徴に追加\ndatas[\"prev_29\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(29))\n\n#30日前の売り上げ個数を特徴に追加\ndatas[\"prev_30\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(30))\n\n#35日前の売り上げ個数を特徴に追加\n#datas[\"prev_35\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(35))\n\n#半年前(182日前)の売り上げ個数を特徴に追加\n#datas[\"prev_182\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(182))\n\n#1年前(365日前)の売り上げ個数を特徴に追加\n#datas[\"prev_365\"] = datas.groupby(\"id\")[\"sell_num\"].transform(lambda x:x.shift(365))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1日前の価格を特徴に追加\ndatas[\"p_prev_1\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(1))\n\n#2日前の価格を特徴に追加\n#datas[\"p_prev_2\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(2))\n\n#3日前の価格を特徴に追加\n#datas[\"p_prev_3\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(3))\n\n#7日前の価格を特徴に追加\n#datas[\"p_prev_7\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(7))\n\n#14日前の価格を特徴に追加\n#datas[\"p_prev_14\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(14))\n\n#28日前の価格を特徴に追加\n#datas[\"p_prev_28\"] = datas.groupby(\"id\")[\"sell_price\"].transform(lambda x:x.shift(28))\n#あまりラグを大きくしすぎるとアイテムによってはデータが全然ない状況に...","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for size in [7, 30]:\n#        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n#            lambda x: x.shift(7).rolling(size).mean()\n#        )\nfor size in [7, 14, 28]:\n        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n            lambda x: x.shift(28).rolling(size).mean()\n        )\n#for size in [7, 30, 60, 90, 180]:\n#        datas[f\"rolling_mean_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n#            lambda x: x.shift(28).rolling(size).mean()\n#        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for size in [7, 30]:\n#        datas[f\"rolling_std_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n#            lambda x: x.shift(7).rolling(size).std()\n#        )\nfor size in [7, 14, 28]:\n        datas[f\"rolling_std_t{size}\"] = datas.groupby([\"id\"])[\"sell_num\"].transform(\n            lambda x: x.shift(28).rolling(size).std()\n        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas[\"price_change_t1\"] = (datas[\"p_prev_1\"] - datas[\"sell_price\"]) / (\n        datas[\"p_prev_1\"]\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas[\"rolling_price_std_t7\"] = datas.groupby([\"id\"])[\"sell_price\"].transform(\n        lambda x: x.rolling(7).std()\n    )\ndatas[\"rolling_price_std_t28\"] = datas.groupby([\"id\"])[\"sell_price\"].transform(\n        lambda x: x.rolling(28).std()\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" attrs = [\n        \"year\",\n        \"quarter\",\n        \"month\",\n        \"week\",\n        \"day\",\n        \"dayofweek\",\n        #\"is_year_end\",\n        #\"is_year_start\",\n        #\"is_quarter_end\",\n        #\"is_quarter_start\",\n        #\"is_month_end\",\n        #\"is_month_start\",\n    ]\n\nfor attr in attrs:\n    dtype = np.int16 if attr == \"year\" else np.int8\n    datas[attr] = getattr(datas[\"date\"].dt, attr).astype(dtype)\n\ndatas[\"is_weekend\"] = datas[\"dayofweek\"].isin([5, 6]).astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datas.to_pickle(\"/kaggle/working/merge_data2.pickle\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}