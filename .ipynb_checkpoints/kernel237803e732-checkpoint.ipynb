{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/accuracylibrary/aswear.pickle\n",
      "/kaggle/input/accuracylibrary/trainX.pickle\n",
      "/kaggle/input/accuracylibrary/trainy.pickle\n",
      "/kaggle/input/accuracylibrary/test.pickle\n",
      "/kaggle/input/m5-forecasting-accuracy/calendar.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\n",
      "/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/accuracylibrary\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/accuracylibrary/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_X = pd.read_pickle(\"trainX.pickle\")\n",
    "train_y = pd.read_pickle(\"trainy.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forestの回帰\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed: 16.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=3, oob_score=False,\n",
       "                      random_state=None, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(n_jobs=3,verbose=True)\n",
    "rfr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/accuracylibrary\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/accuracylibrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('test.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)\n",
    "test.drop([\"id\",\"is_test\",\"sell_num\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:   17.6s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "answear = pd.read_pickle(\"aswear.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend ThreadingBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=3)]: Done 100 out of 100 | elapsed:   17.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6035190961971257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr.score(test,answear.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(y_pred)\n",
    "if max_val < np.max(answear.values):\n",
    "    max_val = np.max(answear.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# グラフ可視化用に加工した場合\n",
    "df_imp = pd.DataFrame(rfr.feature_importances_, columns=[\"importance\"])\n",
    "df_imp[\"Feature Names\"] = train_X.columns\n",
    "df_imp.set_index(\"Feature Names\", inplace=True)\n",
    "df_imp.sort_values(by=\"importance\").tail(10).plot(kind=\"barh\", figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/m5-forecasting-accuracy\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/m5-forecasting-accuracy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"sales_train_validation.csv\")\n",
    "calender = pd.read_csv(\"calendar.csv\")\n",
    "prices = pd.read_csv(\"sell_prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm as tqdm\n",
    "import warnings\n",
    "class WRMSSEEvaluator(object):\n",
    "    \n",
    "    group_ids = ( 'all_id', 'state_id', 'store_id', 'cat_id', 'dept_id', 'item_id',\n",
    "        ['state_id', 'cat_id'],  ['state_id', 'dept_id'], ['store_id', 'cat_id'],\n",
    "        ['store_id', 'dept_id'], ['item_id', 'state_id'], ['item_id', 'store_id'])\n",
    "\n",
    "    def __init__(self, \n",
    "                 train_df: pd.DataFrame, \n",
    "                 valid_df: pd.DataFrame, \n",
    "                 calendar: pd.DataFrame, \n",
    "                 prices: pd.DataFrame):\n",
    "        '''\n",
    "        intialize and calculate weights\n",
    "        '''\n",
    "        warnings.simplefilter('ignore', RuntimeWarning)\n",
    "        print(\"重みとRMSSEを計算中...\")\n",
    "        \n",
    "        \n",
    "        self.calendar = calendar\n",
    "        self.prices = prices\n",
    "        self.train_df = train_df\n",
    "        self.valid_df = valid_df\n",
    "        self.train_target_columns = [i for i in self.train_df.columns if i.startswith('d_')]\n",
    "        \n",
    "        self.weight_columns = self.train_df.iloc[:, -28:].columns.tolist()\n",
    "        self.train_df['all_id'] = \"all\"\n",
    "\n",
    "        self.id_columns = [i for i in self.train_df.columns if not i.startswith('d_')]\n",
    "        self.valid_target_columns = [i for i in self.valid_df.columns if i.startswith('d_')]\n",
    "\n",
    "        #self.dfにid部分をくっつける\n",
    "        #if not all([c in self.valid_df.columns for c in self.id_columns]):\n",
    "        self.valid_df = pd.concat([self.train_df[self.id_columns], self.valid_df],\n",
    "                                 axis=1, \n",
    "                                sort=False)\n",
    "        \n",
    "        self.train_series = self.trans_30490_to_42840(self.train_df, \n",
    "                                                      self.train_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        #{\"all\":{d1総計,d2総計.....}, \"CA\":{d1総計,d2総計....}, .......}\n",
    "        self.valid_series = self.trans_30490_to_42840(self.valid_df, \n",
    "                                                      self.valid_target_columns, \n",
    "                                                      self.group_ids)\n",
    "        #{\"all\":{d-28総計,d-27総計.....}, \"CA\":{d-28総計,d-27総計....}, .......}\n",
    "        self.weights = self.get_weight_df()\n",
    "        self.scale = self.get_scale()\n",
    "        \n",
    "        self.train_series = None\n",
    "        self.train_df = None\n",
    "        self.prices = None\n",
    "        self.calendar = None\n",
    "\n",
    "    def get_scale(self):\n",
    "        '''\n",
    "        scaling factor for each series ignoring starting zeros\n",
    "        '''\n",
    "        scales = []\n",
    "        for i in tqdm(range(len(self.train_series))):\n",
    "            series = self.train_series.iloc[i].values\n",
    "            series = series[np.argmax(series!=0):]\n",
    "            scale = ((series[1:] - series[:-1]) ** 2).mean()\n",
    "            scales.append(scale)\n",
    "        #全区間が0のものはscale=NaN\n",
    "        #scale = ((series[1:] - series[:-1]) ** 2).mean()が0のものがrmsse=infになる\n",
    "        return np.array(scales)\n",
    "    \n",
    "    def get_name(self, i):\n",
    "        '''\n",
    "        convert a str or list of strings to unique string \n",
    "        used for naming each of 42840 series\n",
    "        '''\n",
    "        if type(i) == str or type(i) == int:\n",
    "            return str(i)\n",
    "        else:\n",
    "            return \"--\".join(i)\n",
    "    \n",
    "    def get_weight_df(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        returns weights for each of 42840 series in a dataFrame\n",
    "        \"\"\"\n",
    "        #calenderからd_1,d_2をindexとしたwm_yr_wkのSeriesを作りto_dict()でmapに変換\n",
    "        day_to_week = self.calendar.set_index(\"d\")[\"wm_yr_wk\"].to_dict()\n",
    "        \n",
    "        #item_id,store_idとd-28～のみのリストを作る\n",
    "        weight_df = self.train_df[[\"item_id\", \"store_id\"] + self.weight_columns].set_index(\n",
    "            [\"item_id\", \"store_id\"]\n",
    "        )\n",
    "        \n",
    "        \n",
    "        weight_df = (\n",
    "            weight_df.stack().reset_index().rename(columns={\"level_2\": \"d\", 0: \"value\"})\n",
    "        )\n",
    "       \n",
    "        #d_-28～のデータをwm_yr_wkのmapで上書き\n",
    "        weight_df[\"wm_yr_wk\"] = weight_df[\"d\"].map(day_to_week)\n",
    "        \n",
    "        #priceデータと結合\n",
    "        weight_df = weight_df.merge(\n",
    "            self.prices, how=\"left\", on=[\"item_id\", \"store_id\", \"wm_yr_wk\"]\n",
    "        )\n",
    "        \n",
    "        #item_id,store_id,売上(value)のdfにする\n",
    "        weight_df[\"value\"] = weight_df[\"value\"] * weight_df[\"sell_price\"]\n",
    "        weight_df = weight_df.set_index([\"item_id\", \"store_id\", \"d\"]).unstack(level=2)[\n",
    "            \"value\"\n",
    "        ]\n",
    "        \n",
    "        weight_df = weight_df.loc[\n",
    "            zip(self.train_df.item_id, self.train_df.store_id), :\n",
    "        ].reset_index(drop=True)\n",
    "        weight_df = pd.concat(\n",
    "            [self.train_df[self.id_columns], weight_df], axis=1, sort=False\n",
    "        )\n",
    "        weights_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False)):\n",
    "            lv_weight = weight_df.groupby(group_id)[self.weight_columns].sum().sum(axis=1)\n",
    "            lv_weight = lv_weight / lv_weight.sum()\n",
    "            for i in range(len(lv_weight)):\n",
    "                weights_map[self.get_name(lv_weight.index[i])] = np.array(\n",
    "                    [lv_weight.iloc[i]]\n",
    "                )\n",
    "        weights = pd.DataFrame(weights_map).T / len(self.group_ids)\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def trans_30490_to_42840(self, df, cols, group_ids, dis=False):\n",
    "        '''\n",
    "        transform 30490 series to all 42840 series\n",
    "        '''\n",
    "        series_map = {}\n",
    "        for i, group_id in enumerate(tqdm(self.group_ids, leave=False, disable=dis)):\n",
    "            tr = df.groupby(group_id)[cols].sum()\n",
    "            #1:all_idについてd_1の総計,d2の総計...を出す→shape(1,about1900)\n",
    "            #3:state_idについてd_1の総計,d2の総計...を出す\n",
    "            for j in range(len(tr)):\n",
    "                series_map[self.get_name(tr.index[j])] = tr.iloc[j].values\n",
    "                #2:all_idについて集計したd1の総計...をarrayとしてmapに追加(キーは)\n",
    "        return pd.DataFrame(series_map).T\n",
    "    \n",
    "    def get_rmsse(self, valid_preds) -> pd.Series:\n",
    "        '''\n",
    "        returns rmsse scores for all 42840 series\n",
    "        '''\n",
    "        score = ((self.valid_series - valid_preds) ** 2).mean(axis=1)\n",
    "        rmsse = (score / self.scale).map(np.sqrt)\n",
    "        #scaleが0ならrmsseはinfになる(考慮しなくてよい)\n",
    "        #scaleがinfならrmsseは0になる(考慮しなくてよい)\n",
    "        return rmsse\n",
    "\n",
    "    def score(self, valid_preds: Union[pd.DataFrame, np.ndarray]) -> float:\n",
    "        assert self.valid_df[self.valid_target_columns].shape == valid_preds.shape\n",
    "        \n",
    "        if isinstance(valid_preds, np.ndarray):\n",
    "            valid_preds = pd.DataFrame(valid_preds, columns=self.valid_target_columns)\n",
    "\n",
    "        valid_preds = pd.concat([self.valid_df[self.id_columns], valid_preds],\n",
    "                                axis=1, \n",
    "                                sort=False)\n",
    "        valid_preds = self.trans_30490_to_42840(valid_preds, \n",
    "                                                self.valid_target_columns, \n",
    "                                                self.group_ids, \n",
    "                                                True)\n",
    "        self.rmsse = self.get_rmsse(valid_preds)\n",
    "        self.contributors = pd.concat([self.weights, self.rmsse], \n",
    "                                      axis=1, \n",
    "                                      sort=False).prod(axis=1)\n",
    "        self.contributors.drop(self.contributors[np.isinf(self.contributors.values)].index,inplace=True)\n",
    "        return np.sum(self.contributors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "def calculate_WRMSSE(train_df,calendar,prices,start_d,end_d,y_pred):\n",
    "    print(\"精度計算の前の前準備を実行中...\")\n",
    "    start = 'd_' + str(start_d)\n",
    "    end = 'd_' + str(end_d)\n",
    "    answear = train_df.drop([\"item_id\",\"dept_id\",\"cat_id\",\"store_id\",\"state_id\"],axis=1)\n",
    "    answear = pd.melt(answear ,id_vars=answear.columns[0], var_name='date', value_name='sell_num')\n",
    "    answear[\"date\"] = answear[\"date\"].apply(lambda x:x[2:])\n",
    "    answear[\"date\"] = answear[\"date\"].astype('int16')\n",
    "    answear = answear.loc[(answear[\"date\"] > int(end[2:]) - 28)&(answear[\"date\"] <= int(end[2:]))]\n",
    "    answear.reset_index(inplace=True)\n",
    "    answear.drop(\"index\",axis=1,inplace=True)\n",
    "    keys, i = np.unique(answear[\"id\"], return_index=True)\n",
    "    keys = answear[\"id\"][i[i.argsort()]].values\n",
    "    d = dict(zip(keys, np.arange(len(keys))))\n",
    "    answear[\"category\"] = answear[\"id\"].map(d)\n",
    "    answear.sort_values([\"category\",\"date\"],inplace=True)\n",
    "    answear.reset_index(inplace=True)\n",
    "    answear.drop([\"index\",\"category\"],axis=1,inplace=True)\n",
    "    answear.loc[:,'sell_num']=y_pred\n",
    "    answear[\"Unnamed: 0\"] = answear.index\n",
    "    answear[\"date\"] = answear.groupby(\"id\")[\"Unnamed: 0\"].transform(lambda x:338 + (x % 28))\n",
    "    keys, i = np.unique(answear[\"id\"], return_index=True)\n",
    "    keys = answear[\"id\"][i[i.argsort()]].values\n",
    "    d = dict(zip(keys, np.arange(len(keys))))\n",
    "    answear[\"category\"] = answear[\"id\"].map(d)\n",
    "    df_pivot = pd.pivot_table(answear, index=['category'], columns = ['date'],values=['sell_num'])\n",
    "    drop_columns = list(train_df.columns[6:6+int(start[2:])-1])\n",
    "    drop_columns.extend(train_df.columns[6+int(end[2:]):])\n",
    "    \n",
    "    train_df.drop(train_df.columns[6+end_d:],axis=1,inplace=True)\n",
    "    train_fold_df = train_df.iloc[:, :-28]\n",
    "    valid_fold_df = train_df.iloc[:, -28:].copy()\n",
    "    e = WRMSSEEvaluator(train_fold_df, valid_fold_df, calendar, prices)\n",
    "    del train_fold_df, train_df, calendar, prices\n",
    "    print(\"精度を計算中...\")\n",
    "    wrmsse = e.score(df_pivot.values)\n",
    "    del df_pivot, answear\n",
    "    return wrmsse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精度計算の前の前準備を実行中...\n",
      "重みとRMSSEを計算中...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff359d883d74b548997fe384708b158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=42840.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "精度を計算中...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9523035444650493"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_WRMSSE(train_df,calender,prices,1,1913,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
